{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the objective\n",
    "\n",
    "1. Mnemonics groups\n",
    "2. Strings oer BERT\n",
    "3. Section entropy\n",
    "4. Functions\n",
    "5. Generic information\n",
    "6. All per BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mnemonics\n",
    "\n",
    "data = \"/home/sergio/Documents/TFM/repos/BinaryIntelligence/Models/DATA/groups.csv\"\n",
    "output_history = \"data-vault/scores_mnemonics.json\"\n",
    "model_pickle = \"data-vault/model_mnemonics.pkl\"\n",
    "all_models_pickle = \"data-vault/all_models_mnemonics.pkl\"\n",
    "target = \"groups.feature\"\n",
    "output_image = os.path.abspath(\"data-vault/mnemonics-results.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"/home/sergio/Documents/TFM/data/dataset\"\n",
    "csv = []\n",
    "malware = 0\n",
    "for file in glob.glob(f\"**/{target}\", recursive=True, root_dir=location):\n",
    "    header = []\n",
    "    with open(f\"{location}/{file}\", \"r\") as f:\n",
    "        current_data = json.loads(f.read())\n",
    "    if \"malware\" in file:\n",
    "        malware = 1\n",
    "    header = [\",\".join(list(current_data.keys())) + \",Malware\"]\n",
    "    row = [\",\".join([str(x) for x in list(current_data.values())]) + f\",{malware}\"]\n",
    "    csv.append(row)\n",
    "csv.insert(0, header)\n",
    "\n",
    "output_file = open(data, \"w\")\n",
    "for element in csv:\n",
    "    if len(element[0].split(\",\")) != 15:\n",
    "        continue\n",
    "    output_file.write(f\"{element[0]}\\n\")\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        self.len = self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(X, y, batch_size=4, val_size=0.1, test_size=0.2):\n",
    "    # Split data into train+val and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    # Split train+val data into separate train and val sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_size/(1 - test_size))\n",
    "    \n",
    "    # Wrap the data into our custom datasets\n",
    "    traindata = Data(X_train, y_train)\n",
    "    valdata = Data(X_val, y_val)\n",
    "    testdata = Data(X_test, y_test)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    trainloader = DataLoader(traindata, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    valloader = DataLoader(valdata, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    testloader = DataLoader(testdata, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, valloader, optimizer, criterion, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Progress bar for training data\n",
    "        pbar = tqdm(enumerate(trainloader), total=len(trainloader), desc=\"Training\", leave=True)\n",
    "        for i, data in pbar:\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Update the progress bar.\n",
    "            pbar.set_postfix({'Running Loss': running_loss / (i+1)})\n",
    "\n",
    "        # Calculate accuracy after each epoch on the validation set\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            # Progress bar for validation data\n",
    "            val_pbar = tqdm(valloader, desc=\"Validating\", leave=True)\n",
    "            for data in val_pbar:\n",
    "                inputs, labels = data\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                # Calculate accuracy and update the progress bar.\n",
    "                accuracy = 100 * correct / total\n",
    "                val_pbar.set_postfix({'Validation Accuracy': f'{accuracy:.2f}%'})\n",
    "        \n",
    "        # Print stats at the end of each epoch.\n",
    "        print(f'Epoch: {epoch + 1}, Loss: {running_loss / (i+1):.5f}, Validation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, testloader):\n",
    "    correct, total = 0, 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Accumulate all true labels and predictions for later metrics computation\n",
    "            all_labels.extend(labels.tolist())\n",
    "            all_predictions.extend(predicted.tolist())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # Now we compute precision, recall, f1_score, and confusion matrix with the accumulated labels and predictions\n",
    "    precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "    recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "    confusion = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 score: {f1:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide in characteristics and tags\n",
    "X = df.drop('Malware', axis=1).values\n",
    "y = df['Malware'].values\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_prob=0.5):\n",
    "        super(Network, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob)\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "        return x\n",
    "\n",
    "input_dim = len(X_train[0])\n",
    "hidden_dim = 50\n",
    "dropout_prob = 0.5\n",
    "output_dim = 1\n",
    "clf = Network(input_dim, hidden_dim, output_dim, dropout_prob)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(clf.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader, testloader = get_data_loaders(X, y, batch_size=4)\n",
    "train_model(clf, trainloader, valloader, optimizer, criterion, epochs=5)\n",
    "evaluate_model(clf, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
